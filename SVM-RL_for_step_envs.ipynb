{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8994df9d",
   "metadata": {},
   "source": [
    "# Stochastic Variational Method with RL algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a46171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "import subprocess\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8829f8",
   "metadata": {},
   "source": [
    "## Expoloring environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3a490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Env Name ###### svmEnv-v1\n",
      "###### Observation space ####### \n",
      " Box(-inf, inf, (1,), float32)\n",
      "###### Size of observation space ####### \n",
      " 1\n",
      "###### Action space ####### \n",
      " Box(-1.0, 1.0, (3,), float32)\n",
      "###### Number of actions ####### \n",
      " 3\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "##### State after reset ###### \n",
      " [0.]\n",
      "##### File where will be stored sigmas \n",
      " ./svmCodeSVD/sigmas.dat\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('svm_env:svmEnv-v1', file_sigmas =\"./svmCodeSVD/sigmas.dat\" )\n",
    "\n",
    "print('### Env Name ######', env.unwrapped.spec.id)\n",
    "\n",
    "obs_space = env.observation_space\n",
    "\n",
    "print('###### Observation space ####### \\n', obs_space)\n",
    "\n",
    "state_size = env.observation_space.shape[-1]\n",
    "\n",
    "print('###### Size of observation space ####### \\n', state_size)\n",
    "\n",
    "act_space = env.action_space\n",
    "\n",
    "print('###### Action space ####### \\n', act_space)\n",
    "\n",
    "act_size = env.action_space.shape[-1]\n",
    "\n",
    "print('###### Number of actions ####### \\n', act_size)\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "print('##### State after reset ###### \\n', state)\n",
    "\n",
    "print('##### File where will be stored sigmas \\n', env.file_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae415ae",
   "metadata": {},
   "source": [
    "# Your codes `DDPG` and `PPO`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e81b78",
   "metadata": {},
   "source": [
    "## Functions for saving and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a586189",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save all rewards, energies and princip dims in files during training\n",
    "def create_info_h5(agent, env):\n",
    "    # Check if file exist and creat it\n",
    "    i = 0\n",
    "    while os.path.exists(f'runs_step_envs/run_{i}.hdf5'):\n",
    "        i += 1\n",
    "    dataFile = h5py.File(f'runs_step_envs/run_{i}.hdf5', 'a')\n",
    "    \n",
    "    # Create dataset to store info in hdf5 file\n",
    "    info = {'alg':agent.name, 'env':env.unwrapped.spec.id}\n",
    "    st = h5py.string_dtype(encoding='utf-8')\n",
    "    dataFile.create_dataset('info', dtype=st)\n",
    "    for k in info.keys():\n",
    "        dataFile['info'].attrs[k] = info[k]\n",
    "\n",
    "    # Create dataset to store hyperparams of the model in hdf5 file\n",
    "    hyperparams = {'batch_size':agent.batch_size, 'bootstrap_size':agent.bootstrap_size \\\n",
    "                   , 'gamma':agent.gamma, 'tau':agent.tau,'lr_critic':agent.lr_critic \\\n",
    "                  , 'lr_actor':agent.lr_actor, 'update_every':agent.update_every \\\n",
    "                   , 'transfer_every':agent.transfer_every, 'num_update':agent.num_update \\\n",
    "                  , 'add_noise_every':agent.add_noise_every}\n",
    "    dataFile.create_dataset('hyperparams', dtype='f')\n",
    "    for k in hyperparams.keys():\n",
    "        dataFile['hyperparams'].attrs[k] = hyperparams[k]\n",
    "    \n",
    "    # Create group for rewards, energies, princip dims, actor and critic model\n",
    "    dataFile.create_group('sigmas')\n",
    "    dataFile.create_group('rewards')\n",
    "    dataFile.create_group('energies')\n",
    "    dataFile.create_group('princip_dims')\n",
    "    dataFile.create_group('actor_models')\n",
    "    dataFile.create_group('critic_models')\n",
    "    \n",
    "    # Close and return data file name\n",
    "    dataFile_name = dataFile.filename\n",
    "    dataFile.close()\n",
    "    \n",
    "    return dataFile_name\n",
    "\n",
    "def save_all(dat_file_name, i_ep, sigmas_i_ep, rew_i_ep, en_i_ep, pri_dim_i_ep \\\n",
    "             , act_model_i_ep, cr_model_i_ep):\n",
    "    # Open data file\n",
    "    dat_file = h5py.File(dat_file_name, 'a')\n",
    "    \n",
    "    # Create datasets for rewards, energies, pri dim and store data in it \n",
    "    dat_file['sigmas'].create_dataset(f'sigmas_ep_{i_ep}', dtype='f', data=sigmas_i_ep)\n",
    "    dat_file['rewards'].create_dataset(f'rew_ep_{i_ep}', dtype='f', data=rew_i_ep)\n",
    "    dat_file['energies'].create_dataset(f'en_ep_{i_ep}', dtype='f', data=en_i_ep)\n",
    "    dat_file['princip_dims'].create_dataset(f'pri_dim_ep_{i_ep}', dtype='i', data=pri_dim_i_ep)\n",
    "    \n",
    "    # Store in actor models group the network params at each ep\n",
    "    actor_model = torch.load(act_model_i_ep)\n",
    "    dat_file['actor_models'].create_dataset(f'act_mod_{i_ep}', dtype='f')\n",
    "    for k in actor_model.keys():\n",
    "        dat_file['actor_models'][f'act_mod_{i_ep}'].attrs.create(name=k,data=actor_model[k].cpu().data.numpy())\n",
    "    \n",
    "    # Store in actor models group the network params at each ep\n",
    "    critic_model = torch.load(cr_model_i_ep)\n",
    "    dat_file['critic_models'].create_dataset(f'cri_mod_{i_ep}', dtype='f')\n",
    "    for k in critic_model.keys():\n",
    "        dat_file['critic_models'][f'cri_mod_{i_ep}'].attrs.create(name=k,data=critic_model[k].cpu().data.numpy())\n",
    "    \n",
    "    # Close data file\n",
    "    dat_file.close()\n",
    "    \n",
    "def rm_useless_file(actor_model_file, critic_model_file, file_sigmas):\n",
    "    os.remove(actor_model_file)\n",
    "    os.remove(critic_model_file)\n",
    "    os.remove(file_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c58121",
   "metadata": {},
   "source": [
    "## From my `ddpg_agent.py` code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f8f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import DDPG_agent\n",
    "agent = DDPG_agent(state_size, act_size, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc90e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ddpg algs   \n",
    "def run_ddpg(max_t_step = 10, n_episodes=10):\n",
    "    \n",
    "    # Create h5 file and store info about alg and its hypereparams\n",
    "    dat_file_name = create_info_h5(agent, env)\n",
    "    \n",
    "    for i_ep in range(n_episodes):\n",
    "        state = env.reset()\n",
    "        agent.reset()\n",
    "        rew_i_ep = []\n",
    "        en_i_ep = []\n",
    "        pri_dim_i_ep = []\n",
    "\n",
    "        ## Training loop of each episode\n",
    "        for t_step in range(max_t_step):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            # Save rew, energies, princip dims, act and crit models\n",
    "            rew_i_ep.append(reward)\n",
    "            en_i_ep.append(state[0])\n",
    "            pri_dim_i_ep.append(env.princp_dim)\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        ## Save data during training (to not lose the work done)\n",
    "        save_all(dat_file_name=dat_file_name, i_ep=int(i_ep), sigmas_i_ep=env.actions_taken \\\n",
    "                 , rew_i_ep=rew_i_ep, en_i_ep=en_i_ep, pri_dim_i_ep=pri_dim_i_ep \\\n",
    "                 , act_model_i_ep='checkpoint_actor.pth', cr_model_i_ep='checkpoint_critic.pth')\n",
    "        \n",
    "        print('Episode {} ... Score: {:.3f}'.format(i_ep, np.sum(rew_i_ep)))\n",
    "\n",
    "    rm_useless_file('checkpoint_actor.pth', 'checkpoint_critic.pth', env.file_sigmas)\n",
    "    return dat_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051cc27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [60.13422  56.330334 59.012486]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0249627\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.1964291659288975\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [62.86827  45.008354 51.589306]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.024956\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.1959632515227643\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [61.541958 53.302563 48.138382]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  0.0130006\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.3645911483738349\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [47.20181  42.300724 31.668484]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  0.0111527\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.2360891735834532\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [55.874855 26.353079 48.35269 ]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  0.00286152\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.6595249637547305\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [44.46713  40.024696 33.216297]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  -0.000474876\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.4275137755504286\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [57.92347  50.99568  53.443806]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.00176336\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.33791328933050124\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [57.724438 58.62996  64.898926]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.00294812\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.25552571443323835\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [50.01875  59.16684  53.041317]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  -0.00373215\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.201004688785261\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [42.33975  52.798294 79.1191  ]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  -0.00373706\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.20066325001897312\n",
      "Episode 0 ... Score: -9.075\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [57.76378  34.39235  52.067688]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0255868\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.2398287451629884\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [64.368484 48.113426 51.56232 ]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0249792\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.1975765670783325\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [45.484856 36.655952 41.047153]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  0.0242834\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.149191008303969\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [37.11559  59.236145 45.105263]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  0.00813074\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.0259436961563555\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [37.14702  41.165577 38.77973 ]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  0.00738104\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.9738099602938366\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [46.867683 46.5688   42.26249 ]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  0.0071233\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.9558868589450231\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [52.557816 44.0671   23.568283]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.00586705\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.05254488794106571\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [53.379307 44.804203 26.02651 ]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.0196969\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.9091754627568793\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [42.74816  57.93636   0.938076]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  -0.0197116\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.9101976928718312\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [48.208225   55.790287    0.81762314]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  -0.0197339\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.9117484229101578\n",
      "Episode 1 ... Score: -6.864\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [73.01094  53.233467 37.853813]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0248714\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.1900802129020214\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [70.488335 63.643314 56.88326 ]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0225526\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.028832104701401\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [96.438385 56.707733 65.869774]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  0.0121752\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.307193275116635\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [79.22827  46.674377 57.034943]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  0.0111622\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.2367497984876756\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [81.589935 63.066433 64.93183 ]\n",
      "Basis size (it should be the same of full dim) =   5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this action the energy is:  0.0104117\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1845604310542743\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [77.04065  57.397953 71.33675 ]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  0.0104057\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1841431942726608\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [80.338425 54.125362 66.40992 ]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  0.0103547\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1805966816289537\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [74.71747  46.404324 61.930176]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  0.00969982\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1350566777051885\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [73.84583  31.837729 66.65443 ]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  0.00695308\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.9440498514506697\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [73.674515 34.977325 56.02673 ]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  0.00695145\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.9439365021249966\n",
      "Episode 2 ... Score: -13.335\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [55.54981  53.475254 36.47639 ]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0264224\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.297935920948932\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [56.712086 64.08648  42.543427]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0255675\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.238486633515466\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [41.113823 71.14871  58.69049 ]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  0.0158935\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.5657618626284417\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [40.25649  61.861107 55.364773]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  0.0102803\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1754229455369547\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [44.995052 79.22756  62.469696]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  0.0100862\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1619253356517802\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [60.592545 65.25457  70.86615 ]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  0.00993705\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.1515535246555224\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [73.947296 75.33204  73.62056 ]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  0.00495833\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.8053360064303163\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [87.15953 79.54299 77.54772]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  0.00495661\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.8052163985529202\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [ 75.51166 102.62416  66.55346]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  0.00459399\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.7799999982615127\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [ 76.77208 110.       73.61128]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  0.00440471\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.766837568590903\n",
      "Episode 3 ... Score: -12.748\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [46.718307 47.02207  60.7436  ]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0272403\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.3548122482291127\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [43.426785 39.78161  57.564003]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0271145\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.3460641837079645\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [38.33771  19.910309 33.555984]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  -0.0144113\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.5416176739414489\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [65.318344  12.4057045 50.551018 ]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  -0.0351743\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.9854655567125175\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [54.737854 14.749355 48.432423]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  -0.0400738\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.3261741586311624\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [56.529392 15.207291 60.995865]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  -0.0429865\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.528721754265093\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [65.98666   7.669632 67.91405 ]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.0452159\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.683753034419687\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [39.659718 28.207628 67.775925]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.0454631\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.7009431898221337\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [35.58132 29.86777 77.70724]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  -0.0465141\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.774029166067975\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [47.82356  27.501942 88.696014]\n",
      "Basis size (it should be the same of full dim) =   10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this action the energy is:  -0.0516462\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  3.1309126472204767\n",
      "Episode 4 ... Score: 13.971\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [56.377586 52.58763  45.57889 ]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0272442\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.355083452137162\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [56.56467  55.603527 47.160812]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0265087\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.3039371766577936\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [58.38061  57.058838 50.550137]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  0.0164525\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -1.6046344227820342\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [60.369534 28.631512 43.08304 ]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  0.0060213\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.8792543700554738\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [51.980553 48.944855 39.934032]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  0.0034973\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.7037367639236933\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [61.733612 56.00702  51.17912 ]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  0.0034612\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.7012263892876547\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [58.06438  59.250347 55.6709  ]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  0.00329995\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.6900131507818124\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [54.951786 73.08282  53.60063 ]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  0.000787538\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.5153013679542511\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [75.75928  73.45552  56.865414]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  0.000771193\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.5141647454216738\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [78.57149  67.54126  57.371128]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  0.000512827\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.49619811236864564\n",
      "Episode 5 ... Score: -10.764\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [46.145782 46.36647  51.493713]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0283547\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.432307026467331\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [45.299274 41.040558 48.354042]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0283106\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.429240336122474\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [44.980705 47.84008  19.49363 ]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  -0.0132465\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.4606181067376873\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [49.866196 53.943394 27.441454]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  -0.0182523\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.8087187536372387\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [30.926783 36.756035 24.944672]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  -0.018254\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.8088369707253626\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [50.68148  40.701515 47.506138]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  -0.0220536\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.0730591166280234\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [38.11508  33.26607  53.179424]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.0221382\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.0789421552487628\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [11.678242 35.249027 41.17197 ]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.0706903\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  4.4552291460058395\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [30.555384 33.649605 35.871696]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  -0.073352\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  4.640322336275634\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [30.172674   5.0652275 40.13713  ]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  -0.0798047\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  5.0890396330611125\n",
      "Episode 6 ... Score: 13.553\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [46.79954  47.487293 47.96814 ]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0285599\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.446576524398486\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [50.682663 31.957256 37.66095 ]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0249986\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.198925632672214\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [47.360252 20.402657 17.119736]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  -0.0417537\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.4429935035363854\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [54.929256 29.20084  41.291   ]\n",
      "Basis size (it should be the same of full dim) =   4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this action the energy is:  -0.0420167\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  2.4612823824637458\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [56.80586  11.017632 50.41968 ]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  -0.0596782\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  3.6894536188728013\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [45.94848  11.520611 58.228462]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  -0.0616659\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  3.827677210674759\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [50.47058  11.630043 42.790047]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.0731758\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  4.628069482788939\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [36.949898  7.571907 56.1926  ]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.0777403\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  4.9454823644008705\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [59.092026 13.052189 44.71669 ]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  -0.0795549\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  5.071668675053299\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [44.264194 35.47737  42.869434]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  -0.0819278\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  5.236678868234798\n",
      "Episode 7 ... Score: 27.658\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [40.76117 47.97172 61.25066]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.027184\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.3508971764283118\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [18.789516 50.4925   52.27153 ]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  -0.00359378\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.21062686436388667\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [41.05119 56.02204 50.61859]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  -0.00465633\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -0.1367377073134417\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [58.026577 56.74745  62.705452]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  -0.0110774\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.30978005623830107\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [43.652954 68.90412  62.26089 ]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  -0.0114634\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.3366222891887247\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [23.94368  43.35595  57.396637]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  -0.013674\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.49034622742759737\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [39.14592  42.958862 50.146297]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.0166752\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.6990480655903166\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [30.47157  29.911509 45.218784]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.0231486\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.1492048292723567\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [26.58656  26.16045  33.575066]\n",
      "Basis size (it should be the same of full dim) =   9\n",
      "With this action the energy is:  -0.0300502\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.6291383912688335\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [16.559608 56.662533 25.798992]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  -0.0499429\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  3.0124660788669644\n",
      "Episode 8 ... Score: 4.928\n",
      "#### CALL RESET ####\n",
      "Action chosen at reset:  [0.]\n",
      "Actions taken at reset:  []\n",
      "Energies got at reset:  [0.0]\n",
      "#### CALL STEP #### 1\n",
      "Action chosen at step:  [43.776382 47.481373 61.76506 ]\n",
      "Basis size (it should be the same of full dim) =   1\n",
      "With this action the energy is:  0.0272347\n",
      "With this action the full dim is:  1  and princip dim is:  1\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.354422827232943\n",
      "#### CALL STEP #### 2\n",
      "Action chosen at step:  [38.12827  31.034332 65.484695]\n",
      "Basis size (it should be the same of full dim) =   2\n",
      "With this action the energy is:  0.0237843\n",
      "With this action the full dim is:  2  and princip dim is:  2\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  -2.114483862020146\n",
      "#### CALL STEP #### 3\n",
      "Action chosen at step:  [21.981728 35.076477 71.01799 ]\n",
      "Basis size (it should be the same of full dim) =   3\n",
      "With this action the energy is:  -0.0105805\n",
      "With this action the full dim is:  3  and princip dim is:  3\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.27522589677440124\n",
      "#### CALL STEP #### 4\n",
      "Action chosen at step:  [26.33936  24.474655 69.03002 ]\n",
      "Basis size (it should be the same of full dim) =   4\n",
      "With this action the energy is:  -0.010628\n",
      "With this action the full dim is:  4  and princip dim is:  4\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.27852902129550294\n",
      "#### CALL STEP #### 5\n",
      "Action chosen at step:  [37.616676 27.464746 63.322285]\n",
      "Basis size (it should be the same of full dim) =   5\n",
      "With this action the energy is:  -0.0189964\n",
      "With this action the full dim is:  5  and princip dim is:  5\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  0.8604630685035861\n",
      "#### CALL STEP #### 6\n",
      "Action chosen at step:  [26.01718  42.05137  49.711155]\n",
      "Basis size (it should be the same of full dim) =   6\n",
      "With this action the energy is:  -0.0218915\n",
      "With this action the full dim is:  6  and princip dim is:  6\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.06178676957812\n",
      "#### CALL STEP #### 7\n",
      "Action chosen at step:  [24.958353 52.025803 51.4437  ]\n",
      "Basis size (it should be the same of full dim) =   7\n",
      "With this action the energy is:  -0.0228023\n",
      "With this action the full dim is:  7  and princip dim is:  7\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.1251233130269398\n",
      "#### CALL STEP #### 8\n",
      "Action chosen at step:  [44.61863 40.16587 47.83313]\n",
      "Basis size (it should be the same of full dim) =   8\n",
      "With this action the energy is:  -0.0245714\n",
      "With this action the full dim is:  8  and princip dim is:  8\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.248145578085472\n",
      "#### CALL STEP #### 9\n",
      "Action chosen at step:  [23.597488 36.96131  40.40362 ]\n",
      "Basis size (it should be the same of full dim) =   9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this action the energy is:  -0.0246688\n",
      "With this action the full dim is:  9  and princip dim is:  9\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.254918721840319\n",
      "#### CALL STEP #### 10\n",
      "Action chosen at step:  [30.34208  30.177835 35.993492]\n",
      "Basis size (it should be the same of full dim) =   10\n",
      "With this action the energy is:  -0.0247383\n",
      "With this action the full dim is:  10  and princip dim is:  10\n",
      "#### THE ACTION IS A GOOD ONE #### --> Store the energy got!\n",
      "Reward is  1.2597517145606663\n",
      "Episode 9 ... Score: 2.895\n"
     ]
    }
   ],
   "source": [
    "all_data = run_ddpg(10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9d72c",
   "metadata": {},
   "source": [
    "## Random search as in original SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "scores = []\n",
    "step = 0\n",
    "score = 0.0\n",
    "\n",
    "while True:\n",
    "    print(\".....STEP.....\", step)\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    step = step + 1\n",
    "    score += reward\n",
    "    scores.append(score)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
