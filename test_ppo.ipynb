{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8af5006",
   "metadata": {},
   "source": [
    "# Test PPO agent in pendulum environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcdd255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from ppo_agent import PPO_agent\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fdd63ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Env Name ###### Pendulum-v0\n",
      "###### Observation space ####### \n",
      " Box(-8.0, 8.0, (3,), float32)\n",
      "###### Size of observation space ####### \n",
      " 3\n",
      "###### Action space ####### \n",
      " Box(-2.0, 2.0, (1,), float32)\n",
      "###### Number of actions ####### \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "## Explore environment\n",
    "env = gym.make('Pendulum-v0')\n",
    "print('### Env Name ######', env.unwrapped.spec.id)\n",
    "\n",
    "obs_space = env.observation_space\n",
    "\n",
    "print('###### Observation space ####### \\n', obs_space)\n",
    "\n",
    "state_size = env.observation_space.shape[-1]\n",
    "\n",
    "print('###### Size of observation space ####### \\n', state_size)\n",
    "\n",
    "act_space = env.action_space\n",
    "\n",
    "print('###### Action space ####### \\n', act_space)\n",
    "\n",
    "act_size = env.action_space.shape[-1]\n",
    "\n",
    "print('###### Number of actions ####### \\n', act_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5dc69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define agent\n",
    "agent = PPO_agent(state_size=state_size, action_size=act_size, seed = 2)\n",
    "\n",
    "## Function to save in hdf5 file during learning\n",
    "def save_score(file_name, data):\n",
    "    # Open data file\n",
    "    dat_file = h5py.File(file_name, 'a')\n",
    "    \n",
    "    # Create datasets for score \n",
    "    dat_file.create_dataset('scores', dtype='f', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fbde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ppo(num_iterations = 1000, t_tot_trajs = 2048, length_traj = 200):\n",
    "    scores = []\n",
    "    for k in range(num_iterations):\n",
    "        ## Data for trajectories\n",
    "        trajs_states = []\n",
    "        trajs_acts = []\n",
    "        all_rews = []\n",
    "        rews_t_future = []\n",
    "        trajs_log_pol = []\n",
    "        len_trajs = []\n",
    "        \n",
    "        # Episodic data. Keeps track of rewards per episode, will get cleared at each ep\n",
    "        ep_rews = []\n",
    "        t = 0\n",
    "        i = 0\n",
    "        \n",
    "        ## Run to collect trajs for a maximum of length_traj\n",
    "        while t < t_tot_trajs:\n",
    "            ## Episodic data. Keeps track of rewards per traj\n",
    "            print(f'#####{i}th Traj #####')\n",
    "            i += 1\n",
    "            ep_rews = []\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "\n",
    "            for t_traj in range(length_traj):\n",
    "                env.render()\n",
    "                t += 1\n",
    "                \n",
    "                # Track observations in this batch\n",
    "                trajs_states.append(state)\n",
    "\n",
    "                # Calculate action and log policy and perform a step of th env\n",
    "                action, log_policy = agent.act(state)\n",
    "                state, reward, done, info = env.step(action)\n",
    "                ep_rews.append(reward)\n",
    "\n",
    "                # Track recent reward, action, and action log policy\n",
    "                trajs_acts.append(action)\n",
    "                trajs_log_pol.append(log_policy)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            len_trajs.append(1 + t_traj)\n",
    "            all_rews.append(ep_rews)\n",
    "\n",
    "        # Reshape data as tensors\n",
    "        trajs_states = torch.tensor(trajs_states, dtype=torch.float)\n",
    "        trajs_acts = torch.tensor(trajs_acts, dtype=torch.float)\n",
    "        rews_t_future = agent.compute_return_fut(all_rews)\n",
    "        trajs_log_pol = torch.tensor(trajs_log_pol, dtype=torch.float)\n",
    "\n",
    "        # Run step for learning\n",
    "        agent.step(trajs_states, trajs_acts, trajs_log_pol, rews_t_future, len_trajs)\n",
    "        \n",
    "        # Calculate metrics to print\n",
    "        avg_iter_lens = np.mean(len_trajs)\n",
    "        avg_iter_retur = np.mean([np.sum(ep_rews) for ep_rews in all_rews])\n",
    "        scores.append(avg_iter_retur)\n",
    "        \n",
    "        # Print logging statements\n",
    "        print(flush=True)\n",
    "        print(f\"-------------------- Iteration #{agent.k_step} --------------------\", flush=True)\n",
    "        print(f\"Average Episodic Length: {avg_iter_lens}\", flush=True)\n",
    "        print(f\"Average Episodic Return: {avg_iter_retur}\", flush=True)\n",
    "        print(f\"Timesteps So Far: {agent.t_step}\", flush=True)\n",
    "        print(f\"------------------------------------------------------\", flush=True)\n",
    "        print(flush=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f33f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f94292739f36>:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  trajs_states = torch.tensor(trajs_states, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1275.3155662505358\n",
      "Timesteps So Far: 2200\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1206.714419418078\n",
      "Timesteps So Far: 4400\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #3 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1143.1857152137904\n",
      "Timesteps So Far: 6600\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #4 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1206.9346547404286\n",
      "Timesteps So Far: 8800\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #5 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1285.4578874970064\n",
      "Timesteps So Far: 11000\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #6 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1286.797854455535\n",
      "Timesteps So Far: 13200\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #7 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1322.770061232164\n",
      "Timesteps So Far: 15400\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #8 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1250.3659508807586\n",
      "Timesteps So Far: 17600\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #9 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1033.3578240340014\n",
      "Timesteps So Far: 19800\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #10 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1182.4102800451344\n",
      "Timesteps So Far: 22000\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #11 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1183.6365176184497\n",
      "Timesteps So Far: 24200\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #12 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1378.4523898032182\n",
      "Timesteps So Far: 26400\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #13 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1177.0572069901782\n",
      "Timesteps So Far: 28600\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #14 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1328.4117487602741\n",
      "Timesteps So Far: 30800\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #15 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1056.2261531520758\n",
      "Timesteps So Far: 33000\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #16 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1177.738346808306\n",
      "Timesteps So Far: 35200\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #17 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1238.9365075821495\n",
      "Timesteps So Far: 37400\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #18 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1078.6488247494292\n",
      "Timesteps So Far: 39600\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #19 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1107.6182904733805\n",
      "Timesteps So Far: 41800\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #20 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1370.1789996189275\n",
      "Timesteps So Far: 44000\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #21 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1089.4902473162692\n",
      "Timesteps So Far: 46200\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #22 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1229.3133799748073\n",
      "Timesteps So Far: 48400\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n",
      "#####7th Traj #####\n",
      "#####8th Traj #####\n",
      "#####9th Traj #####\n",
      "#####10th Traj #####\n",
      "\n",
      "-------------------- Iteration #23 --------------------\n",
      "Average Episodic Length: 200.0\n",
      "Average Episodic Return: -1230.122420997977\n",
      "Timesteps So Far: 50600\n",
      "------------------------------------------------------\n",
      "\n",
      "#####0th Traj #####\n",
      "#####1th Traj #####\n",
      "#####2th Traj #####\n",
      "#####3th Traj #####\n",
      "#####4th Traj #####\n",
      "#####5th Traj #####\n",
      "#####6th Traj #####\n"
     ]
    }
   ],
   "source": [
    "scores = run_ppo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d753b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
